{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark \n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType\n",
    "import numpy as np\n",
    "from pyspark.sql.functions import col, struct, spark_partition_id\n",
    "import math\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "#read the csv file and fix the headers\n",
    "df = spark.read.csv(\"C:/Users/nikos/Desktop/partitiondata.csv\", header=False).toDF(\"Id\", \"Text\", \"Latitude\", \"Longitude\")\n",
    "\n",
    "#convert latitude and longitude to float type\n",
    "dataset = df.withColumn(\"Latitude\", regexp_replace('Latitude', '[\"(]', '').cast(\"float\")).withColumn(\"Longitude\", regexp_replace('Longitude', '[)\"]', '').cast(\"float\"))\n",
    "\n",
    "#find the minimum and maximum values of longitude and latitude\n",
    "maxLat = dataset.agg(max(dataset.Latitude)).head()[0]\n",
    "minLat = dataset.agg(min(dataset.Latitude)).head()[0]\n",
    "maxLon = dataset.agg(max(dataset.Longitude)).head()[0]\n",
    "minLon = dataset.agg(min(dataset.Longitude)).head()[0]\n",
    "\n",
    "#the id of each cell of the grid\n",
    "ids = np.zeros(dataset.count())\n",
    "\n",
    "stepLon = (maxLon - minLon) / 10\n",
    "stepLat = (maxLat - minLat) / 10\n",
    "\n",
    "df2 = dataset.withColumn(\"gridID\", ((dataset.Longitude - minLon) / stepLon).cast(\"Int\") * 10 + ((dataset.Latitude - minLat) / stepLat).cast(\"Int\"))\n",
    "\n",
    "#retain the distinct values of the cells which correspond the points\n",
    "mapping = {k: i for i, k in enumerate(\n",
    "    df2.select(\"gridID\").distinct().rdd.flatMap(lambda x: x).collect()\n",
    ")}\n",
    "\n",
    "#partition by the distinct cell id of the grid\n",
    "result = (df2\n",
    "    .select(\"gridID\", struct([c for c in df2.columns]))\n",
    "    .rdd.partitionBy(len(mapping), lambda k: mapping[k])\n",
    "    .values()\n",
    "    .toDF(df2.schema))\n",
    "\n",
    "print(\"Number of partitions: {}\".format(result.rdd.getNumPartitions()))\n",
    "\n",
    "partitions = result.rdd.glom().collect()\n",
    "for i, l in enumerate(partitions): \n",
    "    print (\"partition #{} length: {}\".format(i, len(l)))\n",
    "\n",
    "#result.write.partitionBy('gridID').format(\"csv\").save('C:/Users/nikos/Desktop/gridPartitions')\n",
    "\n",
    "#function which computes the jaccard similarity\n",
    "def jaccard_similarity(str1, str2): \n",
    "        a = set(str1.split()) \n",
    "        b = set(str2.split())\n",
    "        c = a.intersection(b)\n",
    "        return float(len(c)) / (len(a) + len(b) - len(c))\n",
    "\n",
    "#function which computes the euclidean distance\n",
    "def euclidean_distance(object1, object2):\n",
    "    x1 = object1[3]\n",
    "    x2 = object2[3]\n",
    "    y1 = object1[2]\n",
    "    y2 = object2[2]\n",
    "    dist = math.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "    return dist\n",
    "\n",
    "#---------------------------------------------- First function ----------------------------------------------\n",
    "\n",
    "#first function which computes for each point against all, the distance and the textual similarity\n",
    "#retain these that have distance less or equal to theta, and textual similarity greater than e\n",
    "def func1(iterator):\n",
    "    \n",
    "    y = []\n",
    "    \n",
    "    for idx, obj in enumerate(iterator):\n",
    "        x = []\n",
    "        for objec in iterator:\n",
    "            theta = 0.01\n",
    "            e = 0.7\n",
    "            \n",
    "            if (objec!=obj) and (euclidean_distance(obj, objec) < theta) and (jaccard_similarity(obj[1], objec[1]) > e):\n",
    "                x.append(objec[0])\n",
    "                                 \n",
    "        y.append(x)\n",
    "    \n",
    "    return y\n",
    "\n",
    "#apply the first function to each partition\n",
    "nearest_points_1 = result.rdd \\\n",
    "        .mapPartitions(func1) \\\n",
    "        .collect()\n",
    "    \n",
    "print(\"Nearest points for each partition from first function: {}\".format(nearest_points_1))\n",
    "\n",
    "\n",
    "#---------------------------------------------- Second function ----------------------------------------------\n",
    "\n",
    "#second function that sorts the points based on the x axis, and compute the distance for each point from its next points\n",
    "#until the distance is greater than theta, which stops the computation for this point against the others\n",
    "def func2(iterator):\n",
    "    \n",
    "    #retain the values of each partition to a pandas dataframe and sort them based on the longitude\n",
    "    d = pd.DataFrame([p[0], p[1], p[2], p[3]] for p in iterator)\n",
    "    d.columns = ['id', 'text', 'latitude', 'longitude']\n",
    "    d.sort_values(by=['longitude'])\n",
    "    \n",
    "    #create a list of lists which saves the nearest points of each point\n",
    "    points = [[] for x in range(len(d.index))]\n",
    "    \n",
    "    #check each point from its next points, until the distance is greater than theta\n",
    "    for i, row1 in enumerate(d.iterrows()):\n",
    "        for j, row2 in enumerate(d[i+1:].iterrows()):\n",
    "            theta = 0.001\n",
    "            e = 0.7\n",
    "            \n",
    "            if euclidean_distance(row1[1], row2[1]) < theta:\n",
    "                    if jaccard_similarity(row1[1][1], row2[1][1]) > e:\n",
    "                        points[i].append(row2[1][0])\n",
    "                        points[j].append(row1[1][0])\n",
    "            else:\n",
    "                break\n",
    "                                         \n",
    "    return points\n",
    "\n",
    "#apply the second function to each partition\n",
    "nearest_points_2 = result.rdd \\\n",
    "        .mapPartitions(func2) \\\n",
    "        .collect()\n",
    "    \n",
    "print(\"Nearest points for each partition from second function: {}\".format(nearest_points_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
